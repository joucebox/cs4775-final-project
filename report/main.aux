\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{needleman-wunsch}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Background and Motivation}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}The Biological Imperative: RNA Structure and Evolution}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Theoretical Framework: The Viterbi Fallacy and Decision Theory}{1}{subsection.1.3}\protected@file@percent }
\citation{probcons}
\citation{centroidalign}
\citation{rfam}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Review of Existing Literature}{2}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Project Scope and Contributions}{2}{subsection.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Problem Statement}{2}{subsection.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}Objectives}{2}{subsection.1.7}\protected@file@percent }
\citation{rfam}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Contributions}{3}{subsection.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Dataset and Preprocessing}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Pair Hidden Markov Model}{3}{subsection.2.2}\protected@file@percent }
\newlabel{sec:phmm}{{2.2}{3}{Pair Hidden Markov Model}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Emission model}{3}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Start, transition, and end distributions}{4}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Joint probability and log-space parameterization}{4}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Parameter estimation from aligned sequences}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Forward--backward inference}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Viterbi decoding (MAP alignment)}{5}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Maximum expected accuracy (MEA) alignment}{5}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Posterior match probabilities}{5}{subsubsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Objective and weighting}{5}{subsubsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.3}Dynamic programming and reconstruction}{5}{subsubsection.2.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{6}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overall Accuracy: F1 Score and Column Identity}{6}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Precision-Recall Trade-offs and the Role of Gamma}{6}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Analysis of Alignment Uncertainty: The Viterbi Fallacy}{6}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Dataset Characteristics and Alignment Complexity}{7}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Family-Specific Performance}{7}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Statistical Significance and Robustness}{7}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Sensitivity to Parameter Estimation}{7}{subsection.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{8}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Theoretical Implications: Beyond the Best Path}{8}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Computational Trade-offs}{8}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Time and Space Complexity}{8}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Constant-Factor Overheads}{8}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Practical Implications}{8}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Memory Efficiency and Scalability}{8}{subsubsection.4.2.4}\protected@file@percent }
\citation{probcons}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5}Conclusion on Trade-offs}{9}{subsubsection.4.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Weighting Schemes}{9}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Future Directions}{9}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Conclusion}{9}{subsection.4.5}\protected@file@percent }
\newlabel{mylastpage}{{4.5}{9}{Conclusion}{subsection.4.5}{}}
\bibstyle{final_ref}
\bibdata{final}
\bibcite{needleman-wunsch}{{1}{1970}{{Needleman and Wunsch}}{{}}}
\bibcite{probcons}{{2}{2005}{{Do et~al.}}{{}}}
\bibcite{centroidalign}{{3}{2009}{{Hamada et~al.}}{{}}}
\bibcite{rfam}{{4}{2024}{{Ontiveros-Palacios et~al.}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \textbf  {MEA improves F1 relative to Viterbi across a broad range of $\gamma $.} Mean $\Delta $F1 (MEA $-$ Viterbi) over 547 test alignments for each MEA weighting scheme as a function of $\gamma $, with a zoomed view around the Viterbi baseline. Positive values indicate that posterior-based decoding yields higher F1 than MAP decoding; extremely low $\gamma $ may reduce F1 for more permissive settings. }}{11}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:delta_f1_vs_gamma}{{1}{11}{\textbf {MEA improves F1 relative to Viterbi across a broad range of $\gamma $.} Mean $\Delta $F1 (MEA $-$ Viterbi) over 547 test alignments for each MEA weighting scheme as a function of $\gamma $, with a zoomed view around the Viterbi baseline. Positive values indicate that posterior-based decoding yields higher F1 than MAP decoding; extremely low $\gamma $ may reduce F1 for more permissive settings}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {Column identity is stable in moderate $\gamma $ regimes and can match or slightly exceed Viterbi.} Mean column identity versus $\gamma $ for each MEA weighting scheme, with the Viterbi baseline shown as a dashed reference line (and a zoomed view near the baseline). Low $\gamma $ settings can decrease column identity due to permissive matching in uncertain regions, while moderate $\gamma $ settings recover stable, high-quality column structure. }}{11}{figure.caption.2}\protected@file@percent }
\newlabel{fig:column_identity_vs_gamma}{{2}{11}{\textbf {Column identity is stable in moderate $\gamma $ regimes and can match or slightly exceed Viterbi.} Mean column identity versus $\gamma $ for each MEA weighting scheme, with the Viterbi baseline shown as a dashed reference line (and a zoomed view near the baseline). Low $\gamma $ settings can decrease column identity due to permissive matching in uncertain regions, while moderate $\gamma $ settings recover stable, high-quality column structure}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  \textbf  {Precision--recall trade-offs induced by $\gamma $ for each MEA weighting scheme.} Precision, recall, and F1 as functions of $\gamma $ for Power, Threshold, ProbCons-style, and Log-Odds weighting. Dashed horizontal lines indicate the Viterbi baseline metrics. Increasing $\gamma $ generally shifts MEA toward more conservative, higher-precision alignments by emphasizing high-confidence posterior matches. }}{12}{figure.caption.3}\protected@file@percent }
\newlabel{fig:prf_vs_gamma}{{3}{12}{\textbf {Precision--recall trade-offs induced by $\gamma $ for each MEA weighting scheme.} Precision, recall, and F1 as functions of $\gamma $ for Power, Threshold, ProbCons-style, and Log-Odds weighting. Dashed horizontal lines indicate the Viterbi baseline metrics. Increasing $\gamma $ generally shifts MEA toward more conservative, higher-precision alignments by emphasizing high-confidence posterior matches}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  \textbf  {Posterior heatmap case study (RF00236): illustrating the ``Viterbi Fallacy.''} Background shows posterior match probabilities $P_{ij}$. Overlaid markers show the Viterbi (MAP) alignment and the MEA alignment. In ambiguous regions where posterior mass forms a band rather than a single sharp ridge, Viterbi commits to one MAP trajectory, while MEA preferentially follows the posterior-supported ridge (zoomed panels highlight local disagreements). }}{13}{figure.caption.4}\protected@file@percent }
\newlabel{fig:rf00236_heatmap}{{4}{13}{\textbf {Posterior heatmap case study (RF00236): illustrating the ``Viterbi Fallacy.''} Background shows posterior match probabilities $P_{ij}$. Overlaid markers show the Viterbi (MAP) alignment and the MEA alignment. In ambiguous regions where posterior mass forms a band rather than a single sharp ridge, Viterbi commits to one MAP trajectory, while MEA preferentially follows the posterior-supported ridge (zoomed panels highlight local disagreements)}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \textbf  {Posterior mass analysis supports the uncertainty-aware advantage of MEA.} Multi-panel summary of posterior support as a function of $\gamma $: (A) mean posterior mass captured by MEA vs.\ Viterbi, (B) posterior mass gain (MEA $-$ Viterbi), (C) partition of captured posterior mass into shared and method-specific components, and (D) distributional view of mass gain for a representative $\gamma $ setting. Across typical $\gamma $ values, MEA captures comparable or greater posterior support than the single MAP path. }}{14}{figure.caption.5}\protected@file@percent }
\newlabel{fig:posterior_mass}{{5}{14}{\textbf {Posterior mass analysis supports the uncertainty-aware advantage of MEA.} Multi-panel summary of posterior support as a function of $\gamma $: (A) mean posterior mass captured by MEA vs.\ Viterbi, (B) posterior mass gain (MEA $-$ Viterbi), (C) partition of captured posterior mass into shared and method-specific components, and (D) distributional view of mass gain for a representative $\gamma $ setting. Across typical $\gamma $ values, MEA captures comparable or greater posterior support than the single MAP path}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  \textbf  {Posterior efficiency: MEA allocates aligned pairs to higher-confidence posterior matches.} Scatter plots of posterior mass per aligned pair versus number of aligned pairs for MEA and Viterbi, shown for representative $\gamma $ values. MEA tends to achieve higher posterior mass per aligned pair, consistent with selecting matches that are more strongly supported by the posterior distribution. }}{14}{figure.caption.6}\protected@file@percent }
\newlabel{fig:efficiency_scatter}{{6}{14}{\textbf {Posterior efficiency: MEA allocates aligned pairs to higher-confidence posterior matches.} Scatter plots of posterior mass per aligned pair versus number of aligned pairs for MEA and Viterbi, shown for representative $\gamma $ values. MEA tends to achieve higher posterior mass per aligned pair, consistent with selecting matches that are more strongly supported by the posterior distribution}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  \textbf  {Family-specific analysis of F1 improvement highlights contextual benefits of MEA.} Bar plot showing the F1 score differences between our MEA and Viterbi decodings across chosen (top 10, bottom 5) RNA families at $\gamma = 0.5$. The majority of families show improved alignment quality with MEA, but some experienced alignment degradation, showing that MEA's benefits are family-dependent. }}{15}{figure.caption.7}\protected@file@percent }
\newlabel{fig:family_performance}{{7}{15}{\textbf {Family-specific analysis of F1 improvement highlights contextual benefits of MEA.} Bar plot showing the F1 score differences between our MEA and Viterbi decodings across chosen (top 10, bottom 5) RNA families at $\gamma = 0.5$. The majority of families show improved alignment quality with MEA, but some experienced alignment degradation, showing that MEA's benefits are family-dependent}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Parameter Estimation}{16}{subsection.4.6}\protected@file@percent }
\newlabel{alg:param_est}{{4.6}{16}{Parameter Estimation}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Column-wise state labeling}{16}{subsubsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.2}Sufficient statistics}{16}{subsubsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.3}Emissions with pseudocounts}{16}{subsubsection.4.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.4}Transitions and affine-gap parameters}{16}{subsubsection.4.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Forward-Backward Algorithm}{17}{subsection.4.7}\protected@file@percent }
\newlabel{alg:forward_backward}{{4.7}{17}{Forward-Backward Algorithm}{subsection.4.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}Forward recursion}{17}{subsubsection.4.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.2}Backward recursion}{17}{subsubsection.4.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Viterbi Algorithm}{17}{subsection.4.8}\protected@file@percent }
\newlabel{alg:viterbi}{{4.8}{17}{Viterbi Algorithm}{subsection.4.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.8.1}Dynamic programming}{18}{subsubsection.4.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.8.2}Termination and traceback}{18}{subsubsection.4.8.2}\protected@file@percent }
\ttl@finishall
\newlabel{LastPage}{{4.8.2}{18}{Termination and traceback}{page.18}{}}
\gdef\lastpage@lastpage{18}
\gdef\lastpage@lastpageHy{18}
\gdef \@abspage@last{19}
